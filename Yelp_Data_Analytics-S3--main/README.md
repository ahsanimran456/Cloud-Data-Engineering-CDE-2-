# ğŸ“Š Yelp Data Analytics Pipeline using Python, AWS S3 & Snowflake

This project demonstrates a complete data engineering pipeline that processes large-scale Yelp review data (in JSON format), splits it into manageable chunks, uploads the chunks to Amazon S3, and finally loads and transforms the data in Snowflake for structured analytics.

## ğŸ“ Project Structure

â”œâ”€â”€ data/ â”‚ â””â”€â”€ yelp_academic_dataset_review.json # Raw JSON dataset â”œâ”€â”€ scripts/ â”‚ â”œâ”€â”€ split_json.py # Splits large JSON file into chunks â”‚ â”œâ”€â”€ upload_to_s3.py # Uploads chunks to S3 bucket â”‚ â””â”€â”€ snowflake_loader.py # Loads data into Snowflake table â”œâ”€â”€ config/ â”‚ â””â”€â”€ config.yaml # Credentials and configurations â”œâ”€â”€ utils/ â”‚ â””â”€â”€ helpers.py # Utility functions â””â”€â”€ README.md


## âš™ï¸ Tech Stack

- Python â€“ for JSON splitting and automation scripts  
- Amazon S3 â€“ to store processed data chunks  
- Snowflake â€“ to load and flatten JSON into tabular format  
- SQL â€“ for querying structured data  
- JSON â€“ as the source data format

## ğŸš€ Pipeline Flow

1. Raw Yelp JSON data is ingested.
2. Python script splits large JSON into smaller chunks.
3. Chunked files are uploaded to AWS S3.
4. Snowflake loads files directly from S3.
5. JSON is flattened and transformed to tabular form using SQL.
6. The data is now ready for analysis and querying.

## ğŸ§ª How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/zainalvi110/Yelp_Data_Analytics-S3-.git
   cd Yelp_Data_Analytics-S3-

